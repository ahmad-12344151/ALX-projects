{"cells":[{"cell_type":"markdown","metadata":{"id":"5OuAy4CvLDBq"},"source":["<div align=\"center\" style=\" font-size: 80%; text-align: center; margin: 0 auto\">\n","<img src=\"https://raw.githubusercontent.com/Explore-AI/Pictures/master/Python-Notebook-Banners/Code_challenge.png\"  style=\"display: block; margin-left: auto; margin-right: auto;\";/>\n","</div>"],"id":"5OuAy4CvLDBq"},{"cell_type":"markdown","id":"f662d169","metadata":{"id":"f662d169"},"source":["## Integrated Project: Understanding Maji Ndogo's agriculture\n","© ExploreAI Academy"]},{"cell_type":"markdown","id":"26af890c","metadata":{"id":"26af890c"},"source":["In this coding challenge, we will apply all of the skills we learned in Pandas."]},{"cell_type":"markdown","id":"2d230d14","metadata":{"tags":[],"id":"2d230d14"},"source":["⚠️ **Note that this code challenge is graded and will contribute to your overall marks for this module. Submit this notebook for grading. Note that the names of the functions are different in this notebook. Transfer the code in your notebook to this submission notebook**\n","\n","### Instructions\n","\n","- **Do not add or remove cells in this notebook. Do not edit or remove the `### START FUNCTION` or `### END FUNCTION` comments. Do not add any code outside of the functions you are required to edit. Doing any of this will lead to a mark of 0%!**\n","\n","- Answer the questions according to the specifications provided.\n","\n","- Use the given cell in each question to see if your function matches the expected outputs.\n","\n","- Do not hard-code answers to the questions.\n","\n","- The use of StackOverflow, Google, and other online tools is permitted. However, copying a fellow student's code is not permissible and is considered a breach of the Honour code. Doing this will result in a mark of 0%."]},{"cell_type":"markdown","id":"8944ccbc","metadata":{"id":"8944ccbc"},"source":["# Introduction"]},{"cell_type":"markdown","id":"cf2e633f","metadata":{"id":"cf2e633f"},"source":["Hey there, I'm glad you're on board for the Maji Ndogo project AGAIN! Let me walk you through what we're up against and how we'll tackle it.\n","\n","As you know, we're in an ambitious project aimed at automating farming in Maji Ndogo, a place with diverse and challenging agricultural landscapes. Before we dive into the 'how' of farming, we need to figure out the 'where' and 'what'. It's not just about deploying technology; it's about making informed decisions on where to plant specific crops, considering factors like rainfall, soil type, climate, and many others.\n","\n","Our analysis is the groundwork for this entire automation project. We have an array of variables like soil fertility, climate conditions, and geographical data. By understanding these elements, we can recommend the best locations for different crops. It's a bit like solving a complex puzzle – each piece of data is crucial to seeing the bigger picture.\n","\n","We'll start by importing our dataset into a DataFrame. It is currently in an SQLite database, and split into tables. Unlike Power BI or SQL, data analysis in Python happens in a single table. So we will have to brush off those dusty SQL skills to get the data imported. Expect a bit of a mess in the data – it's part of the challenge. We need to clean it up and maybe reshape it to make sense of it. It's like sorting out the tools and materials we need and getting rid of what we don't.\n","\n","Here's where the real fun begins. We'll dive deep into the data, looking for patterns, and correlations. Each clue in the data leads us closer to understanding the best farming practices for Maji Ndogo. I'll be relying on your skills and insights. We'll be working through these steps together, discussing our findings and strategies.\n","\n","Let's gear up and get ready to make a real difference in Maji Ndogo. Ready to get started? Let's dive into our data and see what stories it has to tell us.\n","\n","Sanaa."]},{"cell_type":"markdown","id":"147be850","metadata":{"id":"147be850"},"source":["# Data dictionary"]},{"cell_type":"markdown","id":"bfe8e55e","metadata":{"id":"bfe8e55e"},"source":["**1. Geographic features**\n","\n","- **Field_ID:** A unique identifier for each field (BigInt).\n","\n","- **Elevation:** The elevation of the field above sea level in metres (Float).\n","\n","- **Latitude:** Geographical latitude of the field in degrees (Float).\n","\n","- **Longitude:** Geographical longitude of the field in degrees (Float).\n","\n","- **Location:** Province the field is in (Text).\n","\n","- **Slope:** The slope of the land in the field (Float).\n","\n","**2. Weather features**\n","\n","- **Field_ID:** Corresponding field identifier (BigInt).\n","\n","- **Rainfall:** Amount of rainfall in the area in mm (Float).\n","\n","- **Min_temperature_C:** Average minimum temperature recorded in Celsius (Float).\n","\n","- **Max_temperature_C:** Average maximum temperature recorded in Celsius (Float).\n","\n","- **Ave_temps:** Average temperature in Celcius (Float).\n","\n","**3. Soil and crop features**\n","\n","- **Field_ID:** Corresponding field identifier (BigInt).\n","\n","- **Soil_fertility:** A measure of soil fertility where 0 is infertile soil, and 1 is very fertile soil (Float).\n","\n","- **Soil_type:** Type of soil present in the field (Text).\n","\n","- **pH:** pH level of the soil, which is a measure of how acidic/basic the soil is (Float).\n","\n","**4. Farm management features**\n","\n","- **Field_ID:** Corresponding field identifier (BigInt).\n","\n","- **Pollution_level:** Level of pollution in the area where 0 is unpolluted and 1 is very polluted (Float).\n","\n","- **Plot_size:** Size of the plot in the field (Ha) (Float).\n","\n","- **Chosen_crop:** Type of crop chosen for cultivation (Text).\n","\n","- **Annual_yield:** Annual yield from the field (Float). This is the total output of the field. The field size and type of crop will affect the Annual Yield\n","\n","- **Standard_yield:** Standardised yield expected from the field, normalised per crop (Float). This is independent of field size, or crop type. Multiplying this number by the field size, and average crop yield will give the Annual_Yield."]},{"cell_type":"markdown","id":"936f0f12","metadata":{"id":"936f0f12"},"source":["**Average yield (tons/Ha) per crop type:**\n","- **Coffee:** 1.5\n","\n","- **Wheat:** 3\n","\n","- **Rice:** 4.5\n","\n","- **Maize:** 5.5\n","\n","- **Tea:** 1.2\n","\n","- **Potato:** 20\n","\n","- **Banana:** 30\n","\n","- **Cassava:** 13\n","\n"]},{"cell_type":"markdown","id":"03b39b1a","metadata":{"id":"03b39b1a"},"source":["Alright, let's walk through the process of importing our SQL data from multiple tables into a single DataFrame. This is a crucial step as it sets the foundation for all our subsequent analyses.\n","\n","We're dealing with an SQLite database, `Maji_Ndogo_farm_survey.db`, which contains multiple tables. We'll need to join these tables on a common key to create a comprehensive dataset for our analysis. The common key in our case is `Field_ID`.\n","\n","Here’s how we can do it:"]},{"cell_type":"code","execution_count":2,"id":"aedfcf44","metadata":{"id":"aedfcf44","executionInfo":{"status":"ok","timestamp":1706960573278,"user_tz":0,"elapsed":1183,"user":{"displayName":"ahmad abd elftah","userId":"10172219018220658706"}}},"outputs":[],"source":["import pandas as pd # importing the Pandas package with an alias, pd\n","from sqlalchemy import create_engine, text # Importing the SQL interface. If this fails, run !pip install sqlalchemy in another cell.\n","\n","# Create an engine for the database\n","engine = create_engine('sqlite:///Maji_Ndogo_farm_survey_small.db') #Make sure to have the .db file in the same directory as this notebook, and the file name matches."]},{"cell_type":"markdown","id":"50b71f19","metadata":{"id":"50b71f19"},"source":["Next up, we test if the connection works by printing out all of the table names in the database."]},{"cell_type":"code","execution_count":3,"id":"40ee695d","metadata":{"id":"40ee695d","executionInfo":{"status":"ok","timestamp":1706960575890,"user_tz":0,"elapsed":6,"user":{"displayName":"ahmad abd elftah","userId":"10172219018220658706"}}},"outputs":[],"source":["with engine.connect() as connection:\n","    result = connection.execute(text(\"SELECT name FROM sqlite_master WHERE type='table';\"))\n","    for row in result:\n","        print(row)"]},{"cell_type":"markdown","id":"e5838b83","metadata":{"id":"e5838b83"},"source":["**Expected output:**\n","\n","`('geographic_features',)`\n","\n","`('weather_features',)`\n","\n","`('soil_and_crop_features',)`\n","\n","`('farm_management_features',)`"]},{"cell_type":"markdown","id":"6ce2023f","metadata":{"id":"6ce2023f"},"source":["At this point, we have two choices:\n","\n","1. Either we import each table into a DataFrame, for example, `df_geographic`, then merge them together.\n","\n","2. Use one SQL query and read it into a single DataFrame.\n","\n","While both are equally viable, let's try to use a single SQL query to keep things simple."]},{"cell_type":"markdown","id":"aa9cd3cf","metadata":{"id":"aa9cd3cf"},"source":["Next, we'll write an SQL query to join our tables. Combine all of the tables into a single query, using `Field_ID`."]},{"cell_type":"code","execution_count":5,"id":"0c6a0d9f","metadata":{"id":"0c6a0d9f","executionInfo":{"status":"ok","timestamp":1706963048582,"user_tz":0,"elapsed":273,"user":{"displayName":"ahmad abd elftah","userId":"10172219018220658706"}}},"outputs":[],"source":["sql_query = \"\"\"\n","SELECT *\n","FROM geographic_features\n","JOIN weather_features ON geographic_features.Field_ID = weather_features.Field_ID\n","JOIN soil_and_crop_features ON geographic_features.Field_ID = soil_and_crop_features.Field_ID\n","JOIN farm_management_features ON geographic_features.Field_ID = farm_management_features.Field_ID\n","\"\"\""]},{"cell_type":"markdown","id":"c476ff1c","metadata":{"id":"c476ff1c"},"source":["With our engine and query ready, we'll use `Pandas` to execute the query. The `pd.read_sql_query` function fetches the data and loads it into a DataFrame – essentially transferring our data from the database into a familiar `Pandas` structure. If you use one query, you will import it all into `MD_agric_df`."]},{"cell_type":"code","execution_count":6,"id":"fd4653b4","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":582},"id":"fd4653b4","executionInfo":{"status":"error","timestamp":1706963055758,"user_tz":0,"elapsed":342,"user":{"displayName":"ahmad abd elftah","userId":"10172219018220658706"}},"outputId":"602f731f-c704-4ed5-9381-92dc7dd590ff"},"outputs":[{"output_type":"error","ename":"OperationalError","evalue":"(sqlite3.OperationalError) no such table: geographic_features\n[SQL: \nSELECT *\nFROM geographic_features\nJOIN weather_features ON geographic_features.Field_ID = weather_features.Field_ID\nJOIN soil_and_crop_features ON geographic_features.Field_ID = soil_and_crop_features.Field_ID\nJOIN farm_management_features ON geographic_features.Field_ID = farm_management_features.Field_ID\n]\n(Background on this error at: https://sqlalche.me/e/20/e3q8)","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mOperationalError\u001b[0m                          Traceback (most recent call last)","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sqlalchemy/engine/base.py\u001b[0m in \u001b[0;36m_exec_single_context\u001b[0;34m(self, dialect, context, statement, parameters)\u001b[0m\n\u001b[1;32m   1968\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mevt_handled\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1969\u001b[0;31m                     self.dialect.do_execute(\n\u001b[0m\u001b[1;32m   1970\u001b[0m                         \u001b[0mcursor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr_statement\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meffective_parameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sqlalchemy/engine/default.py\u001b[0m in \u001b[0;36mdo_execute\u001b[0;34m(self, cursor, statement, parameters, context)\u001b[0m\n\u001b[1;32m    921\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdo_execute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcursor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatement\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 922\u001b[0;31m         \u001b[0mcursor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstatement\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    923\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mOperationalError\u001b[0m: no such table: geographic_features","\nThe above exception was the direct cause of the following exception:\n","\u001b[0;31mOperationalError\u001b[0m                          Traceback (most recent call last)","\u001b[0;32m<ipython-input-6-0617a6b26ea4>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;31m# Use Pandas to execute the query and store the result in a DataFrame\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mMD_agric_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_sql_query\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msql_query\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconnection\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/sql.py\u001b[0m in \u001b[0;36mread_sql_query\u001b[0;34m(sql, con, index_col, coerce_float, params, parse_dates, chunksize, dtype)\u001b[0m\n\u001b[1;32m    395\u001b[0m     \"\"\"\n\u001b[1;32m    396\u001b[0m     \u001b[0mpandas_sql\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpandasSQL_builder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcon\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 397\u001b[0;31m     return pandas_sql.read_query(\n\u001b[0m\u001b[1;32m    398\u001b[0m         \u001b[0msql\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    399\u001b[0m         \u001b[0mindex_col\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mindex_col\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/sql.py\u001b[0m in \u001b[0;36mread_query\u001b[0;34m(self, sql, index_col, coerce_float, parse_dates, params, chunksize, dtype)\u001b[0m\n\u001b[1;32m   1558\u001b[0m         \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_convert_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msql\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1559\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1560\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1561\u001b[0m         \u001b[0mcolumns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1562\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/sql.py\u001b[0m in \u001b[0;36mexecute\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1403\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1404\u001b[0m         \u001b[0;34m\"\"\"Simple passthrough to SQLAlchemy connectable\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1405\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconnectable\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecution_options\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1406\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1407\u001b[0m     def read_table(\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sqlalchemy/engine/base.py\u001b[0m in \u001b[0;36mexecute\u001b[0;34m(self, statement, parameters, execution_options)\u001b[0m\n\u001b[1;32m   1414\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mObjectNotExecutableError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstatement\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1415\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1416\u001b[0;31m             return meth(\n\u001b[0m\u001b[1;32m   1417\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1418\u001b[0m                 \u001b[0mdistilled_parameters\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sqlalchemy/sql/elements.py\u001b[0m in \u001b[0;36m_execute_on_connection\u001b[0;34m(self, connection, distilled_params, execution_options)\u001b[0m\n\u001b[1;32m    515\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mTYPE_CHECKING\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    516\u001b[0m                 \u001b[0;32massert\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mExecutable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 517\u001b[0;31m             return connection._execute_clauseelement(\n\u001b[0m\u001b[1;32m    518\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdistilled_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexecution_options\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    519\u001b[0m             )\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sqlalchemy/engine/base.py\u001b[0m in \u001b[0;36m_execute_clauseelement\u001b[0;34m(self, elem, distilled_parameters, execution_options)\u001b[0m\n\u001b[1;32m   1637\u001b[0m             \u001b[0mlinting\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdialect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompiler_linting\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0mcompiler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mWARN_LINTING\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1638\u001b[0m         )\n\u001b[0;32m-> 1639\u001b[0;31m         ret = self._execute_context(\n\u001b[0m\u001b[1;32m   1640\u001b[0m             \u001b[0mdialect\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1641\u001b[0m             \u001b[0mdialect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecution_ctx_cls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_init_compiled\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sqlalchemy/engine/base.py\u001b[0m in \u001b[0;36m_execute_context\u001b[0;34m(self, dialect, constructor, statement, parameters, execution_options, *args, **kw)\u001b[0m\n\u001b[1;32m   1846\u001b[0m             )\n\u001b[1;32m   1847\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1848\u001b[0;31m             return self._exec_single_context(\n\u001b[0m\u001b[1;32m   1849\u001b[0m                 \u001b[0mdialect\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatement\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1850\u001b[0m             )\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sqlalchemy/engine/base.py\u001b[0m in \u001b[0;36m_exec_single_context\u001b[0;34m(self, dialect, context, statement, parameters)\u001b[0m\n\u001b[1;32m   1986\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1987\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mBaseException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1988\u001b[0;31m             self._handle_dbapi_exception(\n\u001b[0m\u001b[1;32m   1989\u001b[0m                 \u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr_statement\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meffective_parameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcursor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1990\u001b[0m             )\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sqlalchemy/engine/base.py\u001b[0m in \u001b[0;36m_handle_dbapi_exception\u001b[0;34m(self, e, statement, parameters, cursor, context, is_sub_exec)\u001b[0m\n\u001b[1;32m   2342\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mshould_wrap\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2343\u001b[0m                 \u001b[0;32massert\u001b[0m \u001b[0msqlalchemy_exception\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2344\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0msqlalchemy_exception\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexc_info\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2345\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2346\u001b[0m                 \u001b[0;32massert\u001b[0m \u001b[0mexc_info\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sqlalchemy/engine/base.py\u001b[0m in \u001b[0;36m_exec_single_context\u001b[0;34m(self, dialect, context, statement, parameters)\u001b[0m\n\u001b[1;32m   1967\u001b[0m                             \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1968\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mevt_handled\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1969\u001b[0;31m                     self.dialect.do_execute(\n\u001b[0m\u001b[1;32m   1970\u001b[0m                         \u001b[0mcursor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr_statement\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meffective_parameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1971\u001b[0m                     )\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sqlalchemy/engine/default.py\u001b[0m in \u001b[0;36mdo_execute\u001b[0;34m(self, cursor, statement, parameters, context)\u001b[0m\n\u001b[1;32m    920\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    921\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdo_execute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcursor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatement\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 922\u001b[0;31m         \u001b[0mcursor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstatement\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    923\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    924\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdo_execute_no_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcursor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatement\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mOperationalError\u001b[0m: (sqlite3.OperationalError) no such table: geographic_features\n[SQL: \nSELECT *\nFROM geographic_features\nJOIN weather_features ON geographic_features.Field_ID = weather_features.Field_ID\nJOIN soil_and_crop_features ON geographic_features.Field_ID = soil_and_crop_features.Field_ID\nJOIN farm_management_features ON geographic_features.Field_ID = farm_management_features.Field_ID\n]\n(Background on this error at: https://sqlalche.me/e/20/e3q8)"]}],"source":["# Create a connection object\n","with engine.connect() as connection:\n","\n","    # Use Pandas to execute the query and store the result in a DataFrame\n","    MD_agric_df = pd.read_sql_query(text(sql_query), connection)"]},{"cell_type":"markdown","id":"6171c658","metadata":{"id":"6171c658"},"source":["Check the DataFrame to see if it loaded correctly."]},{"cell_type":"code","execution_count":7,"id":"3e370c4c","metadata":{"id":"3e370c4c","colab":{"base_uri":"https://localhost:8080/","height":176},"executionInfo":{"status":"error","timestamp":1706963070519,"user_tz":0,"elapsed":308,"user":{"displayName":"ahmad abd elftah","userId":"10172219018220658706"}},"outputId":"9c0e6f80-5a8b-4084-c5e9-5dca3744c756"},"outputs":[{"output_type":"error","ename":"NameError","evalue":"name 'MD_agric_df' is not defined","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-7-3c32a15080aa>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mMD_agric_df\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mNameError\u001b[0m: name 'MD_agric_df' is not defined"]}],"source":["MD_agric_df"]},{"cell_type":"markdown","id":"0b0cc230","metadata":{"id":"0b0cc230"},"source":["Note that there are a couple of `Field_ID` columns in our DataFrame that we need to remove since we're not interested in particular farms for now."]},{"cell_type":"code","execution_count":1,"id":"d8e8d24c","metadata":{"id":"d8e8d24c","colab":{"base_uri":"https://localhost:8080/","height":193},"executionInfo":{"status":"error","timestamp":1706960537490,"user_tz":0,"elapsed":11,"user":{"displayName":"ahmad abd elftah","userId":"10172219018220658706"}},"outputId":"1217404a-8abd-484b-dedb-ee0cbf4760cd"},"outputs":[{"output_type":"error","ename":"NameError","evalue":"name 'MD_agric_df' is not defined","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-1-7770aaff924e>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Now, drop all columns named 'Field_ID'.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mMD_agric_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'Field_ID'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mNameError\u001b[0m: name 'MD_agric_df' is not defined"]}],"source":["# Now, drop all columns named 'Field_ID'.\n","MD_agric_df.drop(columns = 'Field_ID', inplace = True)"]},{"cell_type":"markdown","id":"0837de59","metadata":{"id":"0837de59"},"source":["# Data cleanup"]},{"cell_type":"markdown","id":"8da2b362","metadata":{"id":"8da2b362"},"source":["I noticed some errors in the data. Here's what I picked up:\n","\n","1. There are some swapped column names. Please ensure to use the correct name.\n","\n","2. Some of the crop types contain spelling errors.\n","\n","3.  The `Elevation` column contains some negative values, which are not plausible, so change these to positive values.\n","\n","Use your Pandas skills to clean up the data."]},{"cell_type":"code","execution_count":null,"id":"26b22740","metadata":{"id":"26b22740"},"outputs":[],"source":["# Insert your code here"]},{"cell_type":"markdown","id":"b5c0fed1","metadata":{"id":"b5c0fed1"},"source":["## Final data checkup"]},{"cell_type":"markdown","id":"321fdc11","metadata":{"id":"321fdc11"},"source":["Compare your answers to the expected output to make sure your data is corrected."]},{"cell_type":"code","execution_count":null,"id":"3000a401","metadata":{"id":"3000a401"},"outputs":[],"source":["len(MD_agric_df['Crop_type'].unique())"]},{"cell_type":"markdown","id":"aa8309f1","metadata":{"id":"aa8309f1"},"source":["Expected output: `8`"]},{"cell_type":"code","execution_count":null,"id":"e1371959","metadata":{"id":"e1371959"},"outputs":[],"source":["MD_agric_df['Elevation'].min()"]},{"cell_type":"markdown","id":"1ffa4440","metadata":{"id":"1ffa4440"},"source":["Expected output: `35.910797`"]},{"cell_type":"code","execution_count":null,"id":"87ba5369","metadata":{"id":"87ba5369"},"outputs":[],"source":["MD_agric_df['Annual_yield'].dtype"]},{"cell_type":"markdown","id":"0697d96b","metadata":{"id":"0697d96b"},"source":["Expected outcome: `dtype('float64')`"]},{"cell_type":"markdown","id":"0324a485","metadata":{"id":"0324a485"},"source":["# Analysis"]},{"cell_type":"markdown","id":"9a1fddb1","metadata":{"id":"9a1fddb1"},"source":["## Challenge 1: Uncovering crop preferences"]},{"cell_type":"markdown","id":"55b8dc1b","metadata":{"id":"55b8dc1b"},"source":["Now that we have our data ready, let's delve into understanding where different crops are grown in Maji Ndogo. Our initial step is to focus on tea, a key crop in Maji Ndogo. We need to determine the optimal conditions for its growth. By analyzing data related to elevation, rainfall, and soil type specifically for tea plantations, we'll start to paint a picture of where our farming systems could thrive.\n","\n","**Task:**\n","Create a function that includes only tea fields and returns a tuple with the mean `Rainfall` and the mean `Elevation`. The function should input the full DataFrame, a string value for the crop type to filter by, and output a tuple with rainfall and elevation.\n"]},{"cell_type":"code","execution_count":null,"id":"86896dc5","metadata":{"id":"86896dc5"},"outputs":[],"source":["### START FUNCTION\n","def explore_crop_distribution(df,crop_filter):\n","    # Insert your code here\n","### END FUNCTION"]},{"cell_type":"markdown","id":"9be4474e","metadata":{"id":"9be4474e"},"source":["Input:"]},{"cell_type":"code","execution_count":null,"id":"66ca9510","metadata":{"id":"66ca9510"},"outputs":[],"source":["explore_crop_distribution(MD_agric_df, \"tea\")"]},{"cell_type":"markdown","id":"2ae64880","metadata":{"id":"2ae64880"},"source":["Expected output: `(1534.5079956188388, 775.208667535597)`"]},{"cell_type":"code","execution_count":null,"id":"56d76595","metadata":{"id":"56d76595"},"outputs":[],"source":["explore_crop_distribution(MD_agric_df, \"wheat\")"]},{"cell_type":"markdown","id":"74cd8725","metadata":{"id":"74cd8725"},"source":["Expected output: `(1010.2859910581222, 595.8384148002981)`"]},{"cell_type":"markdown","id":"78795c87","metadata":{"id":"78795c87"},"source":["Repeat this for a couple of crops to get a feeling for where crops are planted in Majio Ndogo."]},{"cell_type":"markdown","id":"2372ccb9","metadata":{"id":"2372ccb9"},"source":["## Challenge 2: Finding fertile grounds\n"]},{"cell_type":"markdown","id":"628c4cc1","metadata":{"id":"628c4cc1"},"source":["With insights into tea cultivation, let's broaden our horizons. Fertile soil is the bedrock of successful farming. By grouping our data by location and soil type, we'll pinpoint where the most fertile soils in Maji Ndogo are. These fertile zones could be prime candidates for diverse crop cultivation, maximising our yield.\n","\n","We’ll group our data by soil type to see where the most fertile grounds are. This information will be vital for deciding where to deploy our farming technology.\n","\n","**Task:** Create a function that groups the data by `Soil_type`, and returns the `Soil_fertility`."]},{"cell_type":"code","execution_count":null,"id":"064f3d6b","metadata":{"id":"064f3d6b"},"outputs":[],"source":["### START FUNCTION\n","def analyse_soil_fertility(df):\n","    # Insert your code here\n","### END FUNCTION"]},{"cell_type":"markdown","id":"39424119","metadata":{"id":"39424119"},"source":["Input:"]},{"cell_type":"code","execution_count":null,"id":"bc11f72f","metadata":{"id":"bc11f72f"},"outputs":[],"source":["analyse_soil_fertility(MD_agric_df)"]},{"cell_type":"markdown","id":"788a7f56","metadata":{"id":"788a7f56"},"source":["Expected output:\n","```python Soil_Type\n","Loamy       0.585868\n","Peaty       0.604882\n","Rocky       0.582368\n","Sandy       0.595669\n","Silt        0.652654\n","Volcanic    0.648894\n","Name: Soil_Fertility, dtype: float64\n","```"]},{"cell_type":"markdown","id":"e9b1845f","metadata":{"id":"e9b1845f"},"source":["Try digging into the data a bit more by aggregating various data to identify some more patterns."]},{"cell_type":"markdown","id":"8e2d8de9","metadata":{"id":"8e2d8de9"},"source":["## Challenge 3: Climate and geography analysis"]},{"cell_type":"markdown","id":"8cc62613","metadata":{"id":"8cc62613"},"source":["Now, let's delve into how climate and geography influence farming. By understanding the relationship between factors like elevation, temperature, and rainfall with crop yields, we can identify the most suitable areas for different crops. This analysis is key to ensuring our automated systems are deployed in locations that will maximise their effectiveness.\n","\n","**Task:** Create a function that takes in a DataFrame and the column name, and groups the data by that column, and aggregates the data by the means of `Elevation`, `Min_temperature_C`, `Max_temperature_C`, and `Rainfall`, and outputs a DataFrame. Please ensure that the order of the columns matches the output."]},{"cell_type":"code","execution_count":null,"id":"29474e68","metadata":{"id":"29474e68"},"outputs":[],"source":["### START FUNCTION\n","def climate_geography_influence(df,column):\n","    # Insert your code here\n","### END FUNCTION"]},{"cell_type":"markdown","id":"6448a869","metadata":{"id":"6448a869"},"source":["Input:"]},{"cell_type":"code","execution_count":null,"id":"4c214f59","metadata":{"id":"4c214f59"},"outputs":[],"source":["climate_geography_influence(MD_agric_df, 'Crop_type')"]},{"cell_type":"markdown","id":"802ce1a4","metadata":{"id":"802ce1a4"},"source":["Expected output:\n","\n","```sql\n","Crop_type \tElevation\tMin_temperature_C\tMax_temperature_C\tRainfall\n","banana\t\t487.973572\t-5.354344\t\t31.988152\t    1659.905687\n","cassava\t\t682.903008\t-3.992113\t\t30.902381\t    1210.543006\n","coffee\t\t647.047734\t-4.028007\t\t30.855189\t    1527.265074\n","maize\t\t680.596982\t-4.497995\t\t30.576692\t    681.010276\n","potato\t\t696.313917\t-4.375334\t\t30.300608\t    660.289064\n","rice\t\t352.858053\t-6.610566\t\t32.727170\t    1632.382642\n","tea\t\t775.208668\t-2.862651\t\t29.950383\t    1534.507996\n","wheat\t\t595.838415\t-4.968107\t\t30.973845\t    1010.285991\n","```"]},{"cell_type":"markdown","id":"977babed","metadata":{"id":"977babed"},"source":["## Challenge 4: Advanced sorting techniques"]},{"cell_type":"markdown","id":"ebf9f6f7","metadata":{"id":"ebf9f6f7"},"source":["Quite often it is better to improve the things you're good at than improving the things you're bad at. So the question is, which crop is the top performer in Maji Ndogo, and under what conditions does it perform well?\n","\n","To answer this, we need to:\n","1. Filter all the fields with an above-average `Standard_yield` (do you have flashbacks to SQL subqueries right now?).\n","2. Then group by <?> crop type, using `count()`.\n","3. Sort the values to get the top crop type on top.\n","4. Retrieve the name of the top index. See the hint below on how to do this.\n","\n","**Task:** Create a function that takes a DataFrame as input, filters, groups and sorts, and outputs a string value of a crop type."]},{"cell_type":"markdown","id":"13b3d881","metadata":{"id":"13b3d881"},"source":["**Hint:** When you have grouped by a column, we can access the labels of that \"index column\" using `.index`. For example:"]},{"cell_type":"code","execution_count":null,"id":"c0deef7c","metadata":{"id":"c0deef7c"},"outputs":[],"source":["grouped_df = MD_agric_df.groupby(\"Soil_type\").mean(numeric_only = True).sort_values(by=\"Elevation\",ascending=False)\n","print(grouped_df.index[0])\n","grouped_df"]},{"cell_type":"code","execution_count":null,"id":"4a4791a6","metadata":{"id":"4a4791a6"},"outputs":[],"source":["### START FUNCTION\n","def find_ideal_fields(df):\n","    # Insert your code here\n","### END FUNCTION"]},{"cell_type":"markdown","id":"7efcc079","metadata":{"id":"7efcc079"},"source":["Input:"]},{"cell_type":"code","execution_count":null,"id":"01448eb0","metadata":{"id":"01448eb0"},"outputs":[],"source":["type(find_ideal_fields(MD_agric_df))"]},{"cell_type":"markdown","id":"8fd44b50","metadata":{"id":"8fd44b50"},"source":["Expected output: `str`"]},{"cell_type":"markdown","id":"ad7289df","metadata":{"id":"ad7289df"},"source":["# Challenge 5: Advanced filtering techniques"]},{"cell_type":"markdown","id":"7956f3ab","metadata":{"id":"7956f3ab"},"source":["Now we know that <?> is our most successful crop, we can look at what makes it successful.\n","\n","Create a function that takes a DataFrame as input, and the type of crop, and filters the DataFrame using the following conditions:\n","1. Filter by crop type.\n","\n","2. Select only rows that have above average `Standard_yield`.\n","\n","3. Select only rows that have `Ave_temps` >= 12 but =< 15.\n","\n","4. Have a `Pollution_level` lower than 0.0001."]},{"cell_type":"code","execution_count":null,"id":"b99d9e12","metadata":{"id":"b99d9e12"},"outputs":[],"source":["### START FUNCTION\n","def find_good_conditions(df, crop_type):\n","    # Insert your code here\n","### END FUNCTION"]},{"cell_type":"markdown","id":"c5bc44d2","metadata":{"id":"c5bc44d2"},"source":["Input:"]},{"cell_type":"code","execution_count":null,"id":"209203d1","metadata":{"id":"209203d1"},"outputs":[],"source":["find_good_conditions(MD_agric_df, \"tea\").shape"]},{"cell_type":"markdown","id":"a522fb89","metadata":{"id":"a522fb89"},"source":["Expected output: `(14, 17)`"]},{"cell_type":"markdown","id":"463b4aa3","metadata":{"id":"463b4aa3"},"source":["# Extra Pandas \"nuggets\""]},{"cell_type":"markdown","id":"c2ffa827","metadata":{"id":"c2ffa827"},"source":["We have not even scratched the surface of Pandas or our dataset. If you remember back to your days with Chidi, it took a while before we could unlock the secrets the survey data had. So, scratch around a bit.\n","\n","On the Pandas front, it's the same. Pandas is a very powerful data analysis tool that takes a while to master. Many of the more advanced methods like window functions, dynamically retrieving or changing data, vectorisation, or processing big data with Pandas are all more advanced topics we encounter in the workplace.\n","\n","But here are two tiny 'nuggets' to upskill in Pandas."]},{"cell_type":"markdown","id":"184dc608","metadata":{"id":"184dc608"},"source":["## df.query()"]},{"cell_type":"markdown","id":"026086fc","metadata":{"id":"026086fc"},"source":["Oh, you're going to love this one... `df.query()` was designed to filter data, but using SQL-like syntax. For example:"]},{"cell_type":"code","execution_count":null,"id":"a3d22c0b","metadata":{"id":"a3d22c0b"},"outputs":[],"source":["MD_agric_df.query('Standard_yield > 0.5 and Soil_type == \"Loamy\"')"]},{"cell_type":"markdown","id":"afdb4b96","metadata":{"id":"afdb4b96"},"source":["Isn't that much easier to read and understand than the one below?"]},{"cell_type":"code","execution_count":null,"id":"b0cb4b7b","metadata":{"id":"b0cb4b7b"},"outputs":[],"source":["MD_agric_df[(MD_agric_df['Standard_yield'] > 0.5) & (MD_agric_df['Soil_type'] == 'Loamy')]"]},{"cell_type":"markdown","id":"ae060c3f","metadata":{"id":"ae060c3f"},"source":["The nice thing is, we can use `in []`, `not in []` to filter with, and also pass in variables using `@variable_name`."]},{"cell_type":"code","execution_count":null,"id":"91cde683","metadata":{"id":"91cde683"},"outputs":[],"source":["soil_types = ['Loamy', 'Sandy', 'Silt']\n","\n","MD_agric_df.query('Soil_type in @soil_types')"]},{"cell_type":"markdown","id":"f5b3f939","metadata":{"id":"f5b3f939"},"source":["# Plotting data with Pandas"]},{"cell_type":"markdown","id":"757d5c23","metadata":{"id":"757d5c23"},"source":["Sometimes we quickly want to see a basic visualisation of our data. we can use `df.plot(kind='bar')` to make a bar plot, `df.plot(kind='hist', bins = 10)` to see the distribution of a data column, or `df.plot(kind='scatter', x='Column_on_x', y='Column_on_y')` to understand the relationship between variables."]},{"cell_type":"code","execution_count":null,"id":"2da1e0bc","metadata":{"id":"2da1e0bc"},"outputs":[],"source":["MD_agric_df.groupby('Crop_type')['Standard_yield'].mean().plot(kind='bar')"]},{"cell_type":"code","execution_count":null,"id":"7fff3aab","metadata":{"id":"7fff3aab"},"outputs":[],"source":["MD_agric_df['Standard_yield'].plot(kind='hist', bins =20)"]},{"cell_type":"code","execution_count":null,"id":"8570713a","metadata":{"id":"8570713a"},"outputs":[],"source":["MD_agric_df.plot(kind='scatter', x = \"Pollution_level\", y = \"Standard_yield\")"]},{"cell_type":"markdown","id":"383a7d2a","metadata":{"id":"383a7d2a"},"source":["We can use these plots to get a quick feel for the data, but we can't really customise these much. For that we need some better tools."]},{"cell_type":"markdown","id":"26fd094b-0fee-46f1-a4b8-73766813c42b","metadata":{"tags":[],"id":"26fd094b-0fee-46f1-a4b8-73766813c42b"},"source":["#  \n","\n","<div align=\"center\" style=\" font-size: 80%; text-align: center; margin: 0 auto\">\n","<img src=\"https://raw.githubusercontent.com/Explore-AI/Pictures/master/ExploreAI_logos/EAI_Blue_Dark.png\"  style=\"width:200px\";/>\n","</div>"]}],"metadata":{"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.1"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":5}